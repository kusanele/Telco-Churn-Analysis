{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa40f114",
   "metadata": {},
   "source": [
    "**<span style=\"color:#0F52BA;font-family:serif; font-size:34px;\"> TELCO CUSTOMER CHURN PREDICTION </span>**\n",
    "\n",
    "Churn prediction models are essential tools for businesses seeking to retain customers, optimize resources, and make data-driven decisions to improve overall performance, profitability, and customer experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0d0f3",
   "metadata": {},
   "source": [
    "**<span style=\"font-family:serif; font-size:24px;\"> TABLE OF CONTENT </span>**\n",
    "\n",
    "1. **<span style=\"font-family:serif; font-size:12px;\"> [TABLE OF CONTENT](1) </span>**\n",
    "    * [What is Customer Churn?](#1)\n",
    "2. **<span style=\"font-family:serif; font-size:12px;\"> [IMPORT IMPORTANT LIBRARIES](#2) </span>**\n",
    "3. **<span style=\"font-family:serif; font-size:12px;\"> [EDA](#3) </span>**\n",
    "4. **<span style=\"font-family:serif; font-size:12px;\"> [DATA ENGINEERING](#4) </span>**\n",
    "5. **<span style=\"font-family:serif; font-size:12px;\"> [[MACHINE LEARNING MODEL](#4) </span>**\n",
    "6. **<span style=\"font-family:serif; font-size:12px;\"> [WHY CHOOSE THIS MODEL / MODELS](#5) </span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0769e91c",
   "metadata": {},
   "source": [
    "<a id = \"1\" ></a>\n",
    "\n",
    "**<span style=\"color:#0F52BA;font-family:serif; font-size:24px;\"> What is Customer Churn ? </span>**\n",
    "\n",
    "Customer churn, also known as customer attrition or customer turnover, refers to the phenomenon where customers discontinue their relationship with a company or stop using its products or services.\n",
    "\n",
    "The reasons for customer churn can vary and may include factors such as dissatisfaction with the product or service, better offers from competitors, changes in customer needs, poor customer service, or a negative customer experience.\n",
    "\n",
    "Customer churn is a critical metric for businesses, as it directly impacts their revenue, profitability, and overall success. A high churn rate can indicate issues with customer satisfaction, loyalty, or product/service quality, while a low churn rate suggests a high level of customer retention and satisfaction.\n",
    "\n",
    "To mitigate churn, businesses often employ various strategies, such as improving customer service, personalizing offers, offering loyalty programs, and using data-driven approaches like churn prediction models (like this one) to identify and target high-risk customers for proactive retention efforts. By understanding the reasons for churn and implementing effective retention strategies, businesses can improve customer loyalty, reduce customer acquisition costs, and enhance their overall growth and profitability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f58826d",
   "metadata": {},
   "source": [
    "<a id = \"2\" ></a>\n",
    "\n",
    "**<span style=\"color:#0F52BA;font-family:serif; font-size:24px;\"> Import important libraries </span>**\n",
    "\n",
    "This code imports the required libraries for the machine learning model and data analysis. \n",
    "\n",
    "It includes the libraries to work with Spark, perform feature engineering (StringIndexer, VectorAssembler), build a RandomForestClassifier, create a pipeline, and visualize the data using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc57ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import count, when\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e696a98",
   "metadata": {},
   "source": [
    "##### **Read the CSV data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296855a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV data\n",
    "\n",
    "df = spark.sql(\"SELECT * FROM Telco_churn_LH.Telco_cust_churn_data LIMIT 1000\")\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e61cc64",
   "metadata": {},
   "source": [
    "<a id = \"2\" ></a>\n",
    "\n",
    "**<span style=\"color:#0F52BA;font-family:serif; font-size:24px;\"> Exploratory Data Analysis </span>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View column data types\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86f8389",
   "metadata": {},
   "source": [
    "The following code performs EDA to analyze the relationship between \"Churn\" and \"gender\":\n",
    "\n",
    "Grouping data by \"gender\" and \"Churn\" and calculating the count of each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec76df75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustered Column Chart comparing churn and gender\n",
    "churn_gender_counts = df.groupBy('gender', 'Churn').agg(count('*').alias('count')).orderBy('gender', 'Churn')\n",
    "churn_gender_total = df.groupBy('gender').agg(count('*').alias('total')).orderBy('gender')\n",
    "churn_gender_joined = churn_gender_counts.join(churn_gender_total, on='gender', how='left')\n",
    "churn_gender_joined = churn_gender_joined.withColumn('percentage', churn_gender_joined['count'] / churn_gender_joined['total'] * 100)\n",
    "\n",
    "churn_gender_joined_pd = churn_gender_joined.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f9d5d",
   "metadata": {},
   "source": [
    "Pivot the data to create the clustered column chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cbfada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the data to create the clustered column chart\n",
    "pivot_data = churn_gender_joined_pd.pivot(index='gender', columns='Churn', values='percentage').reset_index()\n",
    "pivot_data['Total'] = churn_gender_joined_pd.groupby('gender')['percentage'].sum().values\n",
    "\n",
    "bar_width = 0.2\n",
    "index = np.arange(len(pivot_data['gender']))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(index, pivot_data['No'], width=bar_width, label='No Churn')\n",
    "plt.bar(index + bar_width, pivot_data['Yes'], width=bar_width, label='Churn')\n",
    "plt.bar(index + 2 * bar_width, pivot_data['Total'], width=bar_width, label='Total', alpha=0.3)\n",
    "\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Churn vs Gender')\n",
    "plt.xticks(index + bar_width, pivot_data['gender'])\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# Add numbers on top of the bars\n",
    "for i, value in enumerate(pivot_data['No']):\n",
    "    plt.text(i, value + 2, f\"{value:.1f}%\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "for i, value in enumerate(pivot_data['Yes']):\n",
    "    plt.text(i + bar_width, value + 2, f\"{value:.1f}%\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "for i, value in enumerate(pivot_data['Total']):\n",
    "    plt.text(i + 2 * bar_width, value + 2, f\"{value:.1f}%\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Chart for Churn distribution\n",
    "churn_distribution = df.groupBy('Churn').agg(count('*').alias('count')).orderBy('Churn')\n",
    "churn_distribution_pd = churn_distribution.toPandas()\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.pie(churn_distribution_pd['count'], labels=churn_distribution_pd['Churn'], autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Churn Distribution')\n",
    "plt.show()\n",
    "\n",
    "please upload to lakehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aee7b9e",
   "metadata": {},
   "source": [
    "#### Class imbalance\n",
    "\n",
    "\n",
    "\n",
    "The above chat dipict Class imbalance. It means that one class (the minority class) has significantly fewer instances than the other class or classes (the majority class or classes).\n",
    "\n",
    "For example, consider a binary classification problem where the task is to predict whether an email is spam or not spam (ham). If the dataset contains 99% non-spam (ham) emails and only 1% spam emails, it is a class-imbalanced dataset because the spam class is the minority class, and the ham class is the majority class.\n",
    "\n",
    "The main challenge with imbalanced datasets is that standard machine learning algorithms tend to be biased towards the majority class since they are optimized to maximize overall accuracy.\n",
    "\n",
    "\n",
    "To address class imbalance, several techniques can be employed in this case we used ensemble techniques:\n",
    "\n",
    "Techniques like Random Forest or Boosting to combine predictions from multiple models, help improve minority class performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30d4258",
   "metadata": {},
   "source": [
    "<a id = \"3\" ></a>\n",
    "\n",
    "**<span style=\"color:#0F52BA;font-family:serif; font-size:24px;\"> Data Engineering </span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c285ae33",
   "metadata": {},
   "source": [
    "##### **Data Preprocessing:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a319131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"Churn\" column from string to numeric label\n",
    "indexer = StringIndexer(inputCol=\"Churn\", outputCol=\"label\")\n",
    "data = indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f794e58",
   "metadata": {},
   "source": [
    "Here, the \"Churn\" column, which contains the target variable, is converted from string labels (\"Yes\" and \"No\") to numeric labels (0 for \"No\" and 1 for \"Yes\") using the StringIndexer transformer. \n",
    "\n",
    "The resulting DataFrame data contains the new \"label\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb0cf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove unnecessary columns\n",
    "data = data.drop('Index', 'customerID', 'Churn')\n",
    "\n",
    "# Convert categorical variables to numerical using StringIndexer\n",
    "categorical_cols = ['gender', 'Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'InternetService',\n",
    "                    'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
    "                    'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod']\n",
    "\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_index\") for col in categorical_cols]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "data_transformed = pipeline.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd71e485",
   "metadata": {},
   "source": [
    "This part of the code converts categorical variables in the DataFrame into numerical values using StringIndexer.\n",
    "\n",
    "The list categorical_cols contains the names of columns that need to be converted.\n",
    "\n",
    "The code creates a list of StringIndexer transformers for each categorical column and builds a Pipeline to apply these transformers to the data. The transformed DataFrame is stored in data_transformed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824bb12e",
   "metadata": {},
   "source": [
    "<a id = \"4\" ></a>\n",
    "\n",
    "**<span style=\"color:#0F52BA;font-family:serif; font-size:24px;\"> Machine Learning (Random Forest Classifier) </span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb0d856",
   "metadata": {},
   "source": [
    "This step creates a feature vector for the machine learning model. \n",
    "\n",
    "The VectorAssembler is used to combine all the numerical columns (previously created by StringIndexer) into a single column named \"features\". \n",
    "\n",
    "The DataFrame data_final now contains the \"features\" column along with the \"label\" column, which will be used for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b3d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector of features using VectorAssembler\n",
    "feature_cols = [col+\"_index\" for col in categorical_cols]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "data_final = assembler.transform(data_transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29095d",
   "metadata": {},
   "source": [
    "#### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6c2211",
   "metadata": {},
   "source": [
    "The data is split into training and testing sets using an 80-20 ratio. 80% of the data is used for training, and 20% is used for testing the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacba0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "train_data, test_data = data_final.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cd66b1",
   "metadata": {},
   "source": [
    "The Random Forest Classifier is created with the number of trees set to 100. The model is then trained on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05db6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=100)\n",
    "model = rf_classifier.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e55320",
   "metadata": {},
   "source": [
    "The trained model is used to make predictions on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c494f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "predictions = model.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3f2105",
   "metadata": {},
   "source": [
    "The predictions (along with the true labels) from the test data are saved to a CSV file named \"predictions.csv\" for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to a CSV file\n",
    "predictions.select('label', 'prediction').toPandas().to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373e3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the predicted results\n",
    "#predictions.select('Churn', 'prediction', 'probability').show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc7022",
   "metadata": {},
   "source": [
    "The model's performance is evaluated using the BinaryClassificationEvaluator, which calculates the area under the ROC curve (AUC) as a metric. The accuracy is then printed to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3344a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\")\n",
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a9cbc2",
   "metadata": {},
   "source": [
    "### Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9889d4cb",
   "metadata": {},
   "source": [
    "<a id = \"6\" ></a>\n",
    "\n",
    "**<span style=\"color:#0F52BA;font-family:serif; font-size:24px;\"> Why This Model (Random Forest Classifier) </span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518633a0",
   "metadata": {},
   "source": [
    "Some of the reasons why i chose to use the Random Forest Classifier for building this model it because:\n",
    "\n",
    "- Random Forest is an ensemble method that combines multiple decision trees to make predictions. It mitigates the risk of overfitting and improves the model's generalization ability.\n",
    "\n",
    "- Random Forest can effectively handle non-linear relationships between features and the target variable, making it suitable for various real-world problems where linear models might not be sufficient.\n",
    "\n",
    "- Random Forest provides a feature importance score, which helps identify the most influential features in making predictions. This information can be valuable for feature selection and understanding the data.\n",
    "\n",
    "- Random Forest is less sensitive to outliers compared to individual decision trees, as it aggregates predictions from multiple trees.\n",
    "\n",
    "- Implementing and training a Random Forest model is relatively easy. It requires minimal hyperparameter tuning compared to other complex models.\n",
    "\n",
    "- Currently Power Bi uses Spark, which can efficiently handle large datasets and distributed processing. It can scale to big data environments and provide faster model training and prediction times.\n",
    "- works better for data with class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeb42a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
